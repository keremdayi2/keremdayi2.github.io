<!doctype html><html lang=en style=font-size:120%><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content><meta name=description content="Kerem Dayi"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><meta name=keywords content="hugo latex theme blog texify texify2 weastur"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script type=module>
    import renderMathInElement from "https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.mjs";
    renderMathInElement(document.body);
</script><meta property="og:url" content="https://keremdayi2.github.io/research/"><meta property="og:site_name" content="Arif Kerem Dayi"><meta property="og:title" content="Research"><meta property="og:description" content="Kerem Dayi"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://keremdayi2.github.io/images/logo.jpg"><link rel=canonical href=https://keremdayi2.github.io/research/><link rel=alternate type=application/rss+xml href=https://keremdayi2.github.io/research/index.xml title><meta itemprop=name content="Research"><meta itemprop=description content="Kerem Dayi"><meta itemprop=dateModified content="2024-12-01T22:02:26-05:00"><meta itemprop=wordCount content="11"><meta itemprop=image content="https://keremdayi2.github.io/images/logo.jpg"><link media=screen rel=stylesheet href=https://keremdayi2.github.io/css/common.css><link media=screen rel=stylesheet href=https://keremdayi2.github.io/css/content.css><title>Research - </title><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://keremdayi2.github.io/images/logo.jpg"><meta name=twitter:title content="Research"><meta name=twitter:description content="Kerem Dayi"><link rel=stylesheet href=https://keremdayi2.github.io/css/list.css></head><body><div id=wrapper><header id=header><h1><a href=https://keremdayi2.github.io/>Arif Kerem Dayi</a></h1><nav><span class=nav-bar-item><a class=link href=/>Home</a>
</span><span class=nav-bar-item><a class=link href=/research/>Research</a></span></nav></header><main id=main class=archive><h2>Selected Publications</h2><ul><li><a class=link href=https://arxiv.org/abs/2411.15385>Gradient Dynamics for low-rank fine-tuning</a> -- <i>Arxiv preprint,<time>2024</time></i><br><strong>Arif Kerem Dayƒ±</strong>,
Sitan Chen<p><small><strong>TLDR:</strong> We rigorously analyze SGD on learning rank-1 perturbations of two-layer neural networks beyond the kernel regime. We show that fine-tuning sits between the kernel-regime and the feature learning regime, and we can prove complexity rigorous separations between fine-tuning and 'learning from scratch'</small><p><br></li><li><a class=link href=https://arxiv.org/abs/2407.06541>Fast Distributed Optimization over Directed Graphs under Malicious Attacks using Trust</a> -- <i>Arxiv preprint,<time>2024</time></i><br><strong>Arif Kerem Dayƒ±*</strong>,
Orhan Eren Akg√ºn*
Stephanie Gil
Michal Yemini
Angelia Nediƒá<p><small><strong>TLDR:</strong> We design and analyze a projected-gradient based resilient distributed algorithm to make distributed optimization more resilient to adversarial attacks. While ensuring resiliency and distributed computation, this algorithm matches the geometric convergence rate obtained for strongly-convex functions in non-robust, centralized settings.</small><p><br></li><li><a class=link href=https://ieeexplore.ieee.org/abstract/document/10644202>Projected Push-Pull For Distributed Constrained Optimization Over Time-Varying Directed Graphs</a> -- <i>American Controls Conference,<time>2024</time></i><br>Orhan Eren Akg√ºn*
<strong>Arif Kerem Dayƒ±*</strong>
Stephanie Gil
Angelia Nediƒá<p><small><strong>TLDR:</strong> We propose a projected gradient based distributed optimization algorithm that utilizes gradient tracking and lazy updates to achieve geometric convergence on a more general setting compared to previous works. We prove impossibility results that show the importance of lazy updates to our algorithm.</small><p><br></li><li><a class=link href=https://proceedings.mlr.press/v211/akgun23a/akgun23a.pdf>Learning Trust Over Directed Graphs in Multiagent Systems</a> -- <i>Learning for Dynamics and Control (L4DC) Conference,<time>2023</time></i><br>Orhan Eren Akg√ºn
<strong>Arif Kerem Dayƒ±</strong>
Stephanie Gil
Angelia Nediƒá<p><small><strong>TLDR:</strong> We design a distributed local learning algorithm to propagate local trustworthiness observations globally in a graph. The learning guarantees of this algorithm was later used to develop resilient algorithms for applications in multi-agent systems.</small><p><br></li></ul><div class=post-group><small>* Indicates co-primary authorship.</small></div></main><footer id=footer><div><span>¬© 2023</span> - <span>2024</span></div><div><span>Powered by </span><a class=link target=_blank href=https://gohugo.io/>Hugo</a>
<span>üç¶ Theme </span><a class=link target=_blank href=https://texify2.io>TeXify2</a></div><div class=footnote><span>Follow me on <a class=link href=https://github.com/weastur target=_blank rel=noopener>GitHub</a>,
<a class=link href=https://www.linkedin.com/in/weastur/ target=_blank rel=noopener>LinkedIn</a> or
<a class=link href=/index.xml>RSS</a> |
<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en target=_blank rel=noopener>CC BY-NC-SA 4.0</a></span></div></footer></div></body></html>